---
title: 要记要背
date: 2019-04-05 02:41:58
tags:
---
不要太过强调理解的重要性. 理解当然很重要,但是理解了,并不能说明就掌握了,会了,下一次要用的时候就能想起来,能用上了.
作为理科生,也有很多要记要背的东西,理解之后要记忆背诵,记住之后加深理解,二者相辅相成.
如何去掉地里的荒草? 除荒草+种庄稼, 只除荒草不中庄稼,荒草很快就会疯长. 只种庄稼不除荒草,庄稼竞争不过荒草.
思而不学则殆.

1.java中==和equals的区别
    public boolean equals(Object obj) {
        return (this == obj);
    }
    

    基本概念:
        值类型是存储在内存中的堆栈（以后简称栈），而引用类型的变量在栈中仅仅是存储引用类型变量的地址，而其本身则存储在堆中。
        ==操作比较的是两个变量的值是否相等，对于引用型变量表示的是两个变量在堆中存储的地址是否相同，即栈中的内容是否相同。
        equals操作表示的两个变量是否是对同一个对象的引用，即堆中的内容是否相同。
        ==比较的是2个对象的地址，而equals比较的是2个对象的内容。

    常见误区:
        程序在运行的时候会创建一个字符串缓冲池当使用 s2 = "Monday" 这样的表达是创建字符串的时候，
        程序首先会在这个String缓冲池中寻找相同值的对象，在第一个程序中，s1先被放到了池中，所以在s2被创建的时候，
        程序找到了具有相同值的 s1
        使用了 new 操作符，新的"Monday"Sting对象被创建在内存中。他们的值相同，但是位置不同.

         String str1 = new String("hello");
         String str2 = new String("hello");
         String str3 = "hello";
         String str4 = "hello";
         System.out.println(str1==str2);//false  栈里面内容是否相等
         System.out.println(str1.equals(str2));//true 堆里面内容是否相等

        System.out.println(str1==str3);//false
        System.out.println(str1.equals(str3));//true

        System.out.println(str3==str4);//true
        System.out.println(str3.equals(str4));//true
    
    拓展:
        String的intern()方法检查字符串池里是否存在"abc"这么一个字符串，如果存在，就返回池里的字符串；如果不存在，
        该方法会把"abc"添加到字符串池中，然后再返回它的引用。

2.Java中final关键字
    修饰类
        这个类不能被继承
            final类中的成员变量可以根据需要设为final，但是要注意final类中的所有成员方法都会被隐式地指定为final方法。
    修饰方法
        把方法锁定，以防任何继承类修改它的含义  禁止该方法在子类中被覆盖
            类的private方法会隐式地被指定为final方法。
    修饰变量
         如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；
         如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。

         当用final作用于类的成员变量时，成员变量（注意是类的成员变量，局部变量只需要保证在使用之前被初始化赋值即可）
         必须在定义时或者构造器中进行初始化赋值，而且final变量一旦被初始化赋值之后，就不能再被赋值了

         当final变量是基本数据类型以及String类型时，如果在编译期间能知道它的确切值，则编译器会把它当做编译期常量使用。
         也就是说在用到该final变量的地方，相当于直接访问的这个常量，不需要在运行时确定。这种和C语言中的宏替换有点像

        引用变量被final修饰之后，虽然不能再指向其他对象，但是它指向的对象的内容是可变的。

3.cookie和session的区别
    cookie机制采用的是在客户端保持状态的方案，
    而session机制采用的是在服务器端保持状态的方案

    由于采用服务器端保持状态的方案在客户端也需要保存一个标识，所以session机制可能需要借助于cookie机制
    来达到保存标识的目的，但实际上它还有其他选择。

    通过sessionId来区分不同的客户，session是以cookie或url重写为基础的，默认用cookie来实现，系统会创造一个JSESSIONID的输出cookie


4.线程池ThreadPoolExecutor
    目的
        线程是稀缺资源，不能频繁的创建。
        解耦作用；线程的创建与执行完全分开，方便维护。
        应当将其放入一个池子中，可以给其他任务进行复用。
        提高线程的可管理性：线程池可以统一管理、分配、调优和监控
        降低资源消耗：通过重用已经创建的线程来降低线程创建和销毁的消耗
        提高响应速度：任务到达时不需要等待线程创建就可以立即执行    

    四个构造函数,其中的一些参数: 
        int corePoolSize,       核心线程数，默认情况下核心线程会一直存活，即使处于闲置状态也不会受存keepAliveTime限制。
                                除非将allowCoreThreadTimeOut设置为true。

        int maximumPoolSize,    线程池所能容纳的最大线程数。超过这个数的线程将被阻塞。
                                当任务队列为没有设置大小的LinkedBlockingDeque时，这个值无效。

        long keepAliveTime,     非核心线程的闲置超时时间，超过这个时间就会被回收。

        TimeUnit unit,          指定keepAliveTime的单位，如TimeUnit.SECONDS。
                                当将allowCoreThreadTimeOut设置为true时对corePoolSize生效。

        BlockingQueue<Runnable> workQueue,  线程池中的任务队列.
                                            常用的有三种队列，SynchronousQueue,LinkedBlockingDeque,ArrayBlockingQueue。

        ThreadFactory threadFactory,        线程工厂，提供创建新线程的功能

        RejectedExecutionHandler handler    当线程池中的资源已经全部使用，添加新线程被拒绝时，
                                            会调用RejectedExecutionHandler的rejectedExecution方法。
 
    线程池规则

        下面都假设任务队列没有大小限制：

            如果线程数量<=核心线程数量，那么直接启动一个核心线程来执行任务，不会放入队列中。
            如果线程数量>核心线程数，但<=最大线程数，并且任务队列是LinkedBlockingDeque的时候，超过核心线程数量的任务会放在任务队列中排队。
            如果线程数量>核心线程数，但<=最大线程数，并且任务队列是SynchronousQueue的时候，线程池会创建新线程执行任务，这些任务也不会被放在任务队列中。这些线程属于非核心线程，在任务完成后，闲置时间达到了超时时间就会被清除。
            
            如果线程数量>核心线程数，并且>最大线程数，当任务队列是LinkedBlockingDeque，会将超过核心线程的任务放在任务队列中排队。也就是当任务队列是LinkedBlockingDeque并且没有大小限制时，线程池的最大线程数设置是无效的，他的线程数最多不会超过核心线程数。
            如果线程数量>核心线程数，并且>最大线程数，当任务队列是SynchronousQueue的时候，会因为线程池拒绝添加任务而抛出异常。

        任务队列大小有限时

            当LinkedBlockingDeque塞满时，新增的任务会直接创建新线程来执行，当创建的线程数量超过最大线程数量时会抛异常。
            SynchronousQueue没有数量限制。因为他根本不保持这些任务，而是直接交给线程池去执行。当任务数量超过最大线程数时会直接抛异常。


5.volatile
    缓存一致性协议: 保证了每个缓存中使用的共享变量的副本是一致的
        当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，
        会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，
        发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。

    JMM: 并发编程的三个问题
        原子性问题
            一个操作或者多个操作,要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。
        可见性问题
            当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。
        有序性问题
            指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。

    Java对这三个问题的解决方案
        原子性
            Java内存模型只保证了基本读取和赋值是原子性操作,如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现

        可见性
            Java提供了volatile关键字来保证可见性.当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，
            当有其他线程需要读取时，它会去内存中读取新值。

            而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，
            当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。

            通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，
            并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。

        有序性
            通过volatile关键字来保证一定的“有序性”.  可以通过synchronized和Lock来保证有序性

            Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则
                程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作
                锁定规则：一个unLock操作先行发生于后面对同一个锁lock操作
                volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作
                传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C
                线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作
                线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生
                线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行
                对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始

    volatile关键字的两层语义
        保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。
        禁止进行指令重排序。
        (不保证原子性)

            当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，
            且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；

            在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，
            也不能把volatile变量后面的语句放到其前面执行。

    volatile的原理和实现机制
        加入volatile关键字时，会多出一个lock前缀指令
        lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：

        　　1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；

        　　2）它会强制将对缓存的修改操作立即写入主存；

        　　3）如果是写操作，它会导致其他CPU中对应的缓存行无效。

    使用volatile关键字的场景
        对变量的写操作不依赖于当前值     该变量没有包含在具有其他变量的不变式中
            可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。

5.1 Java内存结构

    Java内存区域
        线程共享
            方法区
                又称Non-Heap（非堆），主要用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据，
                根据Java 虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError 异常。
                在方法区中存在一个叫运行时常量池(Runtime Constant Pool）的区域，它主要用于存放编译器生成的各种字面量和符号引用，
                这些内容将在类加载后存放到运行时常量池中，以便后续使用。
            堆
                在虚拟机启动时创建，是Java 虚拟机所管理的内存中最大的一块，主要用于存放对象实例，几乎所有的对象实例都在这里分配内存，
                Java 堆是垃圾收集器管理的主要区域，因此很多时候也被称做GC 堆，如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，
                将会抛出OutOfMemoryError 异常。

        线程私有
            虚拟机栈
                与线程同时创建，总数与线程关联，代表Java方法执行的内存模型。每个方法执行时都会创建一个栈桢来存储方法的的变量表、
                操作数栈、动态链接方法、返回值、返回地址等信息。每个方法从调用直结束就对于一个栈桢在虚拟机栈中的入栈和出栈过程
            本地方法栈
                与虚拟机用到的 Native 方法相关
            程序计数器
                一小块内存空间，主要代表当前线程所执行的字节码行号指示器。字节码解释器工作时，
                通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。

6.ThreadLocal
        ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量。

        首先，在每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，这个threadLocals就是用来存储实际的变量副本的，
        键值为当前ThreadLocal变量，value为变量副本（即T类型的变量）。

    　　 初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，
        并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。

    　　  然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找。


        join的作用
            调用某个线程的这个方法时，这个方法会挂起调用线程，直到被调用线程结束执行，调用线程才会继续执行。
            
            join逻辑
            
                Parent 调用 child.join()，child.join() 再调用 child.join(0) （此时 Parent 会获得 child 实例作为锁，其他线程可以进入 child.join() ，但不可以进入 child.join(0)， 
                因为无法获取锁）。child.join(0) 会不断地检查 child 线程是否是 Active。

                如果 child 线程是 Active，则循环调用 child.wait(0)（为了防止 Spurious wakeup, 需要将 wait(0) 放入 for 循环体中；此时 Parent 会释放 child 实例锁，
                其他线程可以竞争锁并进入 child.join(0)。我们可以得知，可以有多个线程等待某个线程执行完毕）。

                一旦 child 线程不为 Active （状态为 TERMINATED）, child.join(0) 会直接返回到 child.join(), 
                child.join() 会直接返回到 Parent 父线程，Parent 父线程就可以继续运行下去了。
        

        1）实际的通过ThreadLocal创建的副本是存储在每个线程自己的threadLocals中的；

    　　  为何threadLocals的类型ThreadLocalMap的键值为ThreadLocal对象，因为每个线程中可有多个threadLocal变量，就像上面代码中的longLocal和stringLocal；

    　　  在进行get之前，必须先set，否则会报空指针异常；

    　　  如果想在get之前不需要调用set就能正常访问的话，必须重写initialValue()方法。

        
        最常见的ThreadLocal使用场景为 用来解决 数据库连接、Session管理等

        实现:
            内部类
                ThreadLocalMap
                    内部类
                        Entry extends WeakReference<ThreadLocal<?>>
                public T get()



7.HashMap
    数组和链表的结合

    属性
        modCount    用于快速失败，由于HashMap非线程安全，在对HashMap进行迭代时，
                    如果期间其他线程的参与导致HashMap的结构发生变化了（比如put，remove等操作），
                    需要抛出异常ConcurrentModificationException
        threshold   capacity*loadFactory
        initialCapacity
        loadFactory
    方法
        put
            1.如果数组为空,进行数组填充.分配数组空间
            2.如果key为null,存在table[0]或者table[0]的冲突链上
            3.对key的hashcode进一步计算,确保散列均匀
            4.获取在table中的实际位置
            5.如果对应数据已存在,覆盖. 返回旧value
                for (Entry<K,V> e = table[i]; e != null; e = e.next) {
                    Object k;
                    if (e.hash == hash && ((k == e.key) == key) || key.equals(k)) {
                        //替换
                    }
                }

                怎么判断是否已存在? 看新旧key值是否equals, 或者 key的地址一样且hash值一样.



8.垃圾回收算法
    可达性分析
        通过一系列的根节点"GC Roots"的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，
        当一个对象到GC Roots没有引用链相连时，则说明这个对象是不可达的。就会被判断为可被回收的对象。

        GC Roots
            1)虚拟机栈（栈帧中的本地变量表）中引用的对象
            2）方法区中的类静态属性引用的对象。
            3）方法区中的常量引用的对象
            4）本地方法栈中JNI（通常说的Native方法）引用的对象

    标记清除法
        标记阶段和清除阶段
        可能产生的最大的问题就是空间碎片

    复制算法
        将原有的内存空间分为两块相同的存储空间，每次只使用一块，在垃圾回收时，
        将正在使用的内存块中存活对象复制到未使用的那一块内存空间中，之后清除正在使用的内存块中的所有对象，完成垃圾回收。

     标记压缩算法
        在标记清除算法的基础上做了优化,将所有的存活对象压缩到内存空间的一端，之后，清理边界外所有的空间。


    通常新生代回收的频率很高，但是每次回收的时间都很短，而老年代回收的频率比较低，但是被消耗很多的时间

    为了支持高频率的新生代回收，虚拟机可能使用一种叫做卡表的数据结构，卡表为一个比特位集合，
    每一个比特位可以用来表示老年代的某一区域中的所有对象是否持有新生代对象的引用，
    新生代GC时，可以不用花大量时间扫描所有老年代对象，来确定每一个对象的引用关系，而可以先扫描卡表，只有当卡表的标记为1时，
    才需要扫描给定区域的老年代对象，而卡表为0的所在区域的老年代对象，一定不含有新生代对象的引用。

    分区算法
        将整个堆空间划分为连续的不同小区间

        相同的条件下，堆空间越大，一次GC所需的时间就越长，从而产生的停顿时间就越长。为了更好的控制GC产生的停顿时间，
        将一块大的内存区域分割成多个小块，
        根据目标的停顿时间，每次合理的回收若干个小区间，而不是整个堆空间，从而减少一个GC的停顿时间。

9.TCP与UDP
    UDP    
        User Datagram Protocol,用户数据报协议.
        主要作用：将网络数据压缩成数据包的形式。
        数据包：一个二进制数据的传输单位

        在发送端，UDP传送数据的速度仅仅是受应用程序生成数据的速度、计算机的能力和传输带宽的限制；
        在接收端，UDP把每个消息段放在队列中，应用程序每次从队列中读一个消息段。
        
        优势：速度快(减少了TCP协议中提供数据包分组、组装和排序的过程需要的时间消耗)
              较安全(被攻击者利用的漏洞就要少一些)
        劣势: 无法得知其是否安全，完整到达
        应用: DNS、TFTP、SNMP,在生活中音频、视频和普通数据都可以采用UDP协议来进行数据传输，比如腾讯QQ这些社交软件也多采用UDP。

    TCP 
        Transmission Control Protocol 传输控制协议
        主要作用：把数据流分割成适当长度的报文段
        优势：可靠性好
            1.当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，
            将重发这个报文段。当TCP收到发自TCP连接另一端的数据，它将发送一个确认。TCP有延迟确认的功能，在此功能没有打开，
            则是立即确认。功能打开，则由定时器触发确认时间点。
            2.TCP将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。
            如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段（希望发端超时并重发）
            3.既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。
            如果必要，TCP将对收到的数据进行重新排序，将收到的数据以正确的顺序交给应用层。
            4.TCP的接收端必须丢弃重复的数据
            5.量控制。TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据。
            这将防止较快主机致使较慢主机的缓冲区溢出。

        劣势：速度慢，占用系统资源高，易被攻击

        应用 HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议
            浏览器，用的HTTP FlashFXP，用的FTP Outlook，用的POP、SMTP Putty，用的Telnet、SSH QQ文件传输 

        三次握手(SYN=1表示请求连接)
            Client      Server
            1.   -------> SYN=1 seq=J
            2.   SYN=1,ACK=1,ack=J+1,seq=K  <------                通过ack=J+1，Client知道Server是支持TCP的，且理解了自己要建立TCP连接的意图
            3.  ------->ACK=1,ack=K+1                              通过ack=K+1，Server知道Client是支持TCP的，且确实是要建立TCP连接

            建立可靠的通信信道,双方确认自己与对方的发送与接收机能正常,确认双方都支持TCP，告知对方用TCP传输。

                    第一次握手：Client什么都不能确认；Server确认了对方发送正常
                    第二次握手：Client确认了：自己发送、接收正常，对方发送、接收正常；Server确认了：自己接收正常，对方发送正常
                    第三次握手：Client确认了：自己发送、接收正常，对方发送、接收正常；Server确认了：自己发送、接收正常，对方发送接收正常
            
        四次挥手
            Client      Server
            1.  ----->FIN M
            2. ack M+1 <---------
            3.FIN N   <--------
            4.------->ACK=1 ack=K+1

            一方发送FIN只表示自己发完了所有要发的数据，但还允许对方继续把没发完的数据发过来。
        
        拥塞控制
            拥塞控制是一个全局性的过程, 流量控制是点对点通信量的控制
            拥塞原因
                网络能够提供的资源不足以满足用户的需求，这些资源包括缓存空间、链路带宽容量和中间节点的处理能力。

            流量控制
                滑动窗口
                接受方管理发送方发送数据的方式，用来防止接受方可用的数据缓存空间的溢出

            重传
            1、一旦收到确认，发送方关闭重发定时器并且将数据片的备份从重发队列中删除。发送方如果在规定的时间内没有收到数据确认，就重传该数据。
            2、当TCP超时并重传时，它不一定要重传同样的报文段，相反，TCP允许进行重新分组而发送一个较大的报文段，这将有助于提高性能(当然，这个较大的报文段不能够超过接收方声明的MSS)。在协议中这是允许的，因为TCP是使用字节序号而不是报文段序号来进行识别它所要发送的数据和进行确认。
            3、重发定时器
            (1)  每一次一个包含数据的包被发送（包括重发），如果该定时器没有运行则启动它，使得它在RTO秒之后超时（按照当前的RTO值）。
            (2)  当所有的发出数据都被确认之后，关闭该重发定时器。
            (3)  当接收到一个ACK确认一个新的数据，重新启动该重发定时器，使得它在RTO秒之后超时（按照当前的RTO值）

            核心算法
                慢启动
                    先探测一下网络的拥塞程度，也就是由小到大逐渐增加拥塞窗口的大小 
                拥塞避免
                    拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍，这样拥塞窗口按线性规律缓慢增长

                无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络拥塞（没有收到确认，虽然没有收到确认可能是其他原因的分组丢失，
                但是因为无法判定，所以都当作拥塞来处理），就把慢开始门限设置为出现拥塞时的发送窗口大小的一半，然后把拥塞窗口设置为1，执行慢开始算法 


                快速重传
                    要求接收方在收到一个失序的报文端就立即发出重复确认（为的是使发送及早知道有报文段没有到达对方）
                    而不要等到自己发送数据时捎带确认

                    TCP协议保证数据可靠性的一个重要机制，其原理是在发送一个数据以后就开启一个计时器， 
                    在一定时间内如果没有得到发送数据报的ACK报文，那么就重新发送数据，直到发送成功为止。
                    一般来说，重传发生在超时之后，但是如果发送端接收到3个以上 
                    的重复ACK，就应该意识到，数据丢了，需要重新传递。这个机制不需要等到重传定时器溢出，所以叫做快重传

                快速恢复
                    快速重传以后，因为走的不是慢启动而是拥塞避免算法，所以叫快速恢复算法 




10.IP地址分类
    A: 0.0.0.0-127.255.255，其中段0和127不可用
         第一个字节为网络号，后三个字节为主机号。该类IP地址的最前面为“0”，所以地址的网络号取值于1~126之间。
     一般用于大型网络。
    B: 128.0.0.0-191.255.255.255
        前两个字节为网络号，后两个字节为主机号。该类IP地址的最前面为“10”，所以地址的网络号取值于128~191之间。
     一般用于中等规模网络。
    C: 192.0.0.0-223.255.255.255
             前三个字节为网络号，最后一个字节为主机号。该类IP地址的最前面为“110”，所以地址的网络号取值于192~223之间。
     一般用于小型网络。
    D: 224.0.0.0-239.255.255.255
        是多播地址。该类IP地址的最前面为“1110”，所以地址的网络号取值于224~239之间。一般用于多路广播用户
    E: 240.0.0.0-255.255.255.255，其中段255不可用
        是保留地址。该类IP地址的最前面为“1111”，所以地址的网络号取值于240~255之间。

       IP地址由四段组成，每个字段是一个字节，8位，最大值是255

       IP地址对应于OSI参考模型的第三层网络层，工作在网络层的路由器根据目标IP和源IP来判断是否属于同一网段，如果是不同网段，则转发数据包。

    MAC地址
        （Media Access Control，介质访问控制）地址，或称为物理地址，也叫硬件地址，用来定义网络设备的位置
            MAC地址采用十六进制数表示，长度是6个字节（48位），分为前24位和后24位。

            MAC地址对应于OSI参考模型的第二层数据链路层，工作在数据链路层的交换机维护着计算机MAC地址和自身端口的数据库，
            交换机根据收到的数据帧中的“目的MAC地址”字段来转发数据帧。    

        
        在数据通信时，IP地址专注于网络层，网络层设备（如路由器）根据IP地址，将数据包从一个网络传递转发到另外一个网络上；
        而MAC地址专注于数据链路层，数据链路层设备（如交换机）根据MAC地址，将一个数据帧从一个节点传送到相同链路的另一个节点上。
        IP和MAC地址这种映射关系由ARP（Address Resolution Protocol，地址解析协议）协议完成，ARP根据目的IP地址，找到中间节点的MAC地址，
        通过中间节点传送，从而最终到达目的网络。
    

11.进程间通信
    方式
        信号
            用于通知接收进程某个事件已经发生
            
            进程间的软件中断通知和处理机制(SIGKILL SIGSTOP SIGCONT)
            接收处理
                捕获
                忽略
                屏蔽

        管道
            普通管道PIPE： 通常有两种限制,一是单工,只能单向传输;二是只能在父子或者兄弟进程间使用.
            流管道s_pipe: 去除了第一种限制,为半双工，只能在父子或兄弟进程间使用，可以双向传输.
            命名管道:name_pipe：去除了第二种限制,可以在许多并不相关的进程之间进行通讯.
            
            进程间基于内存文件的通信机制
            子进程从父进程继承文件描述符
            缺省文件描述符
            一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

        消息队列
            操作系统维护的以字节序列为基本单位的间接通信机制
            由消息的链表，存放在内核中并由消息队列标识符标识
            消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

        共享内存
            把同一个物理内存区域映射到多个进程的内存地址空间的通信机制

        信号量
            信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，
            防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

        套接字
            可用于不同机器间的进程通信


    
12.数据库索引
    平衡树  

    聚集索引

    非聚集索引和聚集索引的区别在于， 通过聚集索引可以查到需要查找的数据， 
    而通过非聚集索引可以查到记录对应的主键值 ， 再使用主键的值通过聚集索引查找到需要的数据

    覆盖索引
        不使用聚集索引就能查询出所需要的数据

13.http协议
    HTTP请求由状态行、请求头、请求正文三部分组成：

        状态行：包括请求方式Method、资源路径URL、协议版本Version；

        请求头：包括一些访问的域名、用户代理、Cookie等信息；

        请求正文：就是HTTP请求的数据。

    HTTP响应由三部分组成：状态行、响应头、响应正文；

        状态行：包括协议版本Version、状态码Status Code、回应短语；

        响应头：包括搭建服务器的软件，发送响应的时间，回应数据的格式等信息；

        响应正文：就是响应的具体数据。


    常见状态码的含义

        200---OK/请求已经正常处理完毕

        301---/请求永久重定向

        302---/请求临时重定向

        304---/请求被重定向到客户端本地缓存

        400---/客户端请求存在语法错误

        401---/客户端请求没有经过授权

        403---/客户端的请求被服务器拒绝，一般为客户端没有访问权限

        404---/客户端请求的URL在服务端不存在

        500---/服务端永久错误

        503---/服务端发生临时错误


14.http和https
    HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，
    就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。

    安全套接字层超文本传输协议HTTPS，为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL协议，SSL依靠证书来验证服务器的身份，
    并为浏览器和服务器之间的通信加密。
    HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。
    SSL Secure Sockets Layer

    HTTPS和HTTP的区别主要如下：
    　　1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。
    　　2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。
    　　3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
    　　4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

    客户端在使用HTTPS方式与Web服务器通信时有以下几个步骤
    　　（1）客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。
    　　（2）Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。
    　　（3）客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。
    　　（4）客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。
    　　（5）Web服务器利用自己的私钥解密出会话密钥。
    　　（6）Web服务器利用会话密钥加密与客户端之间的通信。

15.

多线程区:
    1. synchronized和reentrantlock异同

        相同点
            都实现了多线程同步和内存可见性语义
            都是可重入锁
            不同点

        实现机制不同 
            synchronized通过java对象头锁标记和Monitor对象实现 
            reentrantlock通过CAS、ASQ（AbstractQueuedSynchronizer）和locksupport（用于阻塞和解除阻塞）实现 
            synchronized依赖jvm内存模型保证包含共享变量的多线程内存可见性
             reentrantlock通过ASQ的volatile state保证包含共享变量的多线程内存可见性

        使用方式不同 
            synchronized可以修饰实例方法（锁住实例对象）、静态方法（锁住类对象）、代码块（显示指定锁对象）
             reentrantlock显示调用trylock()/lock()方法，需要在finally块中释放锁

        功能丰富程度不同 
            reentrantlock提供有限时间等候锁（设置过期时间）、可中断锁（lockInterruptibly）、condition（提供await、signal等方法）等丰富语义 
            reentrantlock提供公平锁和非公平锁实现 synchronized不可设置等待时间、不可被中断（interrupted）


    2. concurrenthashmap为何读不用加锁

        jdk1.7
            1）HashEntry中的key、hash、next 均为final 型，只能表头插入、删除结点
            2）HashEntry类的value域被声明为volatile型
            3）不允许用null作为键和值，当读线程读到某个HashEntry的 value域的值为null时，便知道产生了冲突——发生了重排序现象（put设置新value对象的字节码指令重排序），需要加锁后重新读入这个value值
            4）volatile变量count协调读写线程之间的内存可见性，写操作后修改count，读操作先读count，根据happen-before传递性原则写操作的修改读操作能够看到
        jdk1.8
            1）Node的val和next均为volatile型
            2）tabAt和casTabAt对应的unsafe操作实现了volatile语义

算法区:
    1.最小区间：k个有序的数组，找到最小区间使k个数组中每个数组至少有一个数在区间中

    2.快排
```java
        public static void quicksort(int[] arr) {
            quicksort(arr, 0, arr.length - 1);
        }
        
        private static void quicksort(int[] arr, int low, int high) {
            if (low < high) {
                int pivot = partition(arr, low, high);
                quicksort(arr, low, pivot - 1);
                quicksort(arr, pivot + 1, high);
            }
        }

        private static int partition(int[] arr, int low, int high) {
            int pivot = arr[low];
            while (low < high) {
                while (low < high && pivot <= arr[high]) {
                    high--;
                }
                arr[low] = arr[high];
                while (low < high && arr[low] <= pivot) {
                    low++;
                }
                arr[high] = arr[low];
            }
            arr[low] = pivot;
            return low;
        }
 ```   
    3.TOP k
        1.快排思路
```java
            private static int partition(int[] arr, int low, int high) {
                int pivot = arr[low];
                while (low < high) {
                    while (low < high && pivot >= arr[high]) {
                        high--;
                    }
                    arr[low] = arr[high];
                    while (low < high && pivot <= arr[low]) {
                        low++;
                    }
                    arr[high] = arr[low];
                }
                arr[low] = pivot;
                return low;
            }

            public static int topK(int[] arr, int k) {
                int low = 0;
                int high = arr.length - 1;
                int index = partition(arr, low, high);
                while (index != k) {
                    if (index > k) {
                        high = index - 1;
                        partition(arr, low, high);
                    } else {
                        low = index + 1;
                        partition(arr, low, high);
                    }
                }
            }

```
linux区
    常用命令
        删除指定日期之前的文件
            find /data1/yulei/user_mq/logs -mtime +7 -type f | xargs rm -rf

Redis区
     Redis是一个Key-value存储系统。它支持存储的value类型很多，包括String（字符串）、链表(list)、set（集合）、zset（有序集合） hash。
     Redis支持各种不同方式的排序。可以把周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件。

    缓存穿透
        缓存系统按照KEY去查询VALUE,当KEY对应的VALUE一定不存在的时候并对KEY并发请求量很大的时候，就会对后端造成很大的压力。

        解决办法
            布隆过滤器
                将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。
            缓存层缓存空值
                如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
                   存储层更新代码了，缓存层还是空值。（优化：后台设置时主动删除空值，并缓存把值进去）

    缓存雪崩（缓存失效）
         如果缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。

         解决办法
            1.在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。
            2.可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存
            3.不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀
            4.做二级缓存，或者双缓存策略。A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期。

    热点key
        将热点key对应value并缓存在客户端本地，并且设置一个失效时间。
        对于每次读请求，将首先检查key是否存在于本地缓存中，如果存在则直接返回，如果不存在再去访问分布式缓存的机器。

        将热点key分散为多个子key，然后存储到缓存集群的不同机器上，这些子key对应的value都和热点key是一样的。
        当通过热点key去查询数据时，通过某种hash算法随机选择一个子key，然后再去访问缓存机器，将热点分散到了多个子key上。


    淘汰策略
        noeviction: 不删除策略, 达到最大内存限制时, 如果需要更多内存, 直接返回错误信息。 大多数写命令都会导致占用更多的内存(有极少数会例外, 如 DEL )。
        allkeys-lru: 所有key通用; 优先删除最近最少使用(less recently used ,LRU) 的 key。
        volatile-lru: 只限于设置了 expire 的部分; 优先删除最近最少使用(less recently used ,LRU) 的 key。
        allkeys-random: 所有key通用; 随机删除一部分 key。
        volatile-random: 只限于设置了 expire 的部分; 随机删除一部分 key。
        volatile-ttl: 只限于设置了 expire 的部分; 优先删除剩余时间(time to live,TTL) 短的key。

        如果分为热数据与冷数据, 推荐使用 allkeys-lru 策略。 也就是, 其中一部分key经常被读写. 如果不确定具体的业务特征,
         那么 allkeys-lru 是一个很好的选择。

         如果需要循环读写所有的key, 或者各个key的访问频率差不多, 可以使用 allkeys-random 策略, 即读写所有元素的概率差不多。

         假如要让 Redis 根据 TTL 来筛选需要删除的key, 请使用 volatile-ttl 策略。
         
         volatile-lru 和 volatile-random 策略主要应用场景是: 既有缓存,又有持久key的实例中。
          一般来说, 像这类场景, 应该使用两个单独的 Redis 实例。
          值得一提的是, 设置 expire 会消耗额外的内存, 所以使用 allkeys-lru 策略, 可以更高效地利用内存, 因为这样就可以不再设置过期时间了。