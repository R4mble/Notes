---
title: Elasticsearch
date: 2019-04-27 23:33:37
tags: [读书笔记]
categories: [Elasticsearch]
---

> 全文搜索引擎,分布式文档数据库,每个字段均是被索引的数据且可被搜索.

> 分片机制, 复制机制.

> Lucene是一个Java开发的全文检索引擎工具包, Elasticsearch是Lucene加了一层json.

>  Elasticsearch内置了对分布式集群和分布式索引的管理.

## Lucene倒排索引
根据属性的值来查找记录.
表现为: 一个关键词,它的频度,位置.
 1. 取得关键词. 去掉无意义介词,大小写统一,动词时态还原,过滤标点.
 2. 建立倒排索引. 关键词所在的文章号,关键词的位置, 频度
 3. 实现. 词典文件,频率文件,位置文件; 词典文件保留指向另外两个文件的指针.
 4. 压缩算法. 关键词压缩: <前缀长度,后缀>. 数字压缩:只保存与上一个值的差值.
 5. 查询单词时,Lucene对词典二元查找
 
 对应关系: "文章号" 对应 "文章中所有关键词"  
 倒排索引: "关键词" 对应 "拥有该关键词的所有文章"  
 关键词在文章中出现的位置和次数:  记录该词是文章中第几个关键词,(节约索引空间,词组查询快)  
 关键词按照字符顺序排列,可以使用二元搜索算法快速定位关键词.  
 
 | 关键词 | 文章号[出现频率] | 出现位置 |
 | :----: | :----: | :----: |
 | he | 2[1] | 1
 | live | 1[2] 2[1] | 2,5 2|
 以上三列分别作为词典文件,频率文件,位置文件保存.
 词典文件不仅保存了关键词,还保存了指向频率文件和位置文件的指针.
 
 假设查询单词"live", Lucene先对词典二元查找,找到该词,通过指向频率文件的指针读出
 所有文章号.返回结果.
 
 
         
Lucene的评分机制, 查询DSL, 底层索引控制.

## Elasticsearch术语
    索引词(term): 能够被索引的精确值.
    文本(text): 普通的非结构化文字, 会被分析成一个个的索引词.
    分析(analysis): 将文本转换为索引词的过程.
    集群(cluster)
    节点(node)
    路由(routing): 存储文档时通过散列值进行选择分片.
    分片(shard): 单个Lucene实例. 索引是指向主分片和副本分片的逻辑空间,索引可以
        分解为多个分片,Elasticsearch会自动管理集群中的所有分片.
    主分片(primary shard): 默认一个索引有5个主分片.
    副本分片(replica shard): 每一个分片有零个或多个副本.
        当主分片失败时,可以从副本中选择一个作为主分片.
        并行操作提高性能和吞吐量.
    索引(index) 具有相同结构的文档集合
    类型(type) 索引中可以定义一个或多个类型,类型是索引的逻辑分区.
                一个类型被定义为具有一组公共字段的文档.
                如: 一个博客平台的所有数据存储在一个索引中,在这个索引中,定义一种
                类型为用户数据,一种类型为博客数据,一种类型为评论数据.
    文档(document) JSON格式的字符串,像关系数据库中的一行.每个文档都有一个类型和一个ID
    映射(mapping) 像关系数据库的表结构,每一个索引都有一个映射,定义了索引中的每一个字段类型,以及一个索引范围内的设置.
    字段(field) 像关系数据库中的列.每个字段对应一个类型: 整数,字符串,对象等.
    来源字段(source field) 原文档被存储在_source这个字段中.
    主键(ID) 

## API约定
    多索引参数
        同时查询多个索引中的数据, 通配符 * : test*表示查询所有以test开头的索引. -test表示排除test
    日期筛选
        <static_name{date_math_expr{date_format|time_zone}}>
        static_name: 索引名称
        date_math_expr: 动态日期计算表达式
        date_format: 日期格式
        time_zone: 时区,默认UTC
    通用参数
        pretty
        human
		
> POST改变对象的当前状态, PUT创建一个对象.		
		
> Elasticsearch从5.X引入text和keyword，keyword适用于不分词字段，搜索时只能完全匹配.
			   6.X彻底移除string, "index"的值只能是boolean变量.

## 准实时索引的实现
新收到的数据写到新的索引文件里.
Lucene把每次生成的倒排索引, 叫做一个段. 使用一个commit文件记录索引内所有的segment. 
生成segment的数据来源就是内存中的buffer.

1) 当前索引有3个segment可用.
2) 新接收的数据进入内存buffer
3) 内存buffer生成一个新的segment, 刷到文件系统缓存中(默认1秒间隔, Lucene即可检索到这个新的segment), 
   再由文件系统缓存刷到磁盘, commit文件同步更新

    curl -XPOST http://127.0.0.1:9200/logstash-2015.06.21/_settings -d'
    { “refresh_interval”: “10s” }


### translog
ES把数据写入内存buffer的同时,另外记录了一个translog日志.
在文件系统缓存刷到磁盘的过程中如果发生了异常, ES会从commit位置开始, 恢复整个translog文件中的记录, 保证数据一致性.
真正把segment刷到磁盘, 且commit文件进行更新时, translog文件才清空.称为flush
ES默认每30分钟或当translog文件大于512MB时 主动进行一次flush
ES默认每5秒强制刷新translog日志到磁盘上.(如果数据没备份,发生故障时确实有可能丢失5秒数据)

### segment merge
独立线程来进行segment数据归并.